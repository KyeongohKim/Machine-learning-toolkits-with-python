# Machine-learning-toolkits-with-python
Practical machine learning toolkits with Python 

## Ensemble methods (Bagging classifiers vs. Voting classifiers)

- Bagging & voting classifiers with Scikit-learn
- "Ensembles are well established as a method for obtaining highly accurate classiers by combining less accurate ones." (Dietterich 2000)
- Related papers
 1) Dietterich, T. G. (2000). Ensemble methods in machine learning. Multiple classifier systems, 1857, 1-15.
 2) Breiman, L. (1996). Bagging predictors. Machine learning, 24(2), 123-140.

![alt text](http://www.datakit.cn/images/machinelearning/EnsembleLearning_Combining_classifiers.jpg)

## Hyperparmeter tuning (Grid search vs. Random search)

- Grid search & random search with Scikit-learn
- "Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time." (Bergstra and Bengio 2012)
- Related paper: Bergstra, J., & Bengio, Y. (2012). Random search for hyper-parameter optimization. Journal of Machine Learning Research, 13(Feb), 281-305.

![alt text](https://cdn-images-1.medium.com/max/1600/1*ZTlQm_WRcrNqL-nLnx6GJA.png)


## Model selection (Bootstrap vs. Cross-validation)

- Bootstrap & cross-validation with Scikit-learn
- "Our results indicate that for real-world datasets similar to ours, the best method to use for model selection is ten-fold stratified cross validation, even if computation power allows using more folds
- Related paper: Kohavi, R. (1995, August). A study of cross-validation and bootstrap for accuracy estimation and model selection. In Ijcai (Vol. 14, No. 2, pp. 1137-1145).

![alt_text](https://sebastianraschka.com/images/faq/evaluate-a-model/k-fold.png)
